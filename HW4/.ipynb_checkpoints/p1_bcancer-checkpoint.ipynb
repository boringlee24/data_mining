{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inclusive-router",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pdb\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.datasets as datasets\n",
    "import copy\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import metrics\n",
    "import math\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "earned-estimate",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PCA(X_scale):\n",
    "    num_n, num_d = X_scale.shape\n",
    "    cov = np.matmul(np.transpose(X_scale), X_scale) / num_n\n",
    "    value, vector = np.linalg.eig(cov)\n",
    "    index = value.argsort()[::-1]\n",
    "    value_sorted = value[index]\n",
    "    total_var, k = sum(value_sorted), 0\n",
    "    curr_sum = 0\n",
    "    for i, eig in enumerate(value_sorted):\n",
    "        curr_sum += eig\n",
    "        if curr_sum / total_var >= 0.99:\n",
    "            k = i+1\n",
    "            break\n",
    "    k_ind = index[:k]\n",
    "    principle = vector[:,k_ind]\n",
    "    return np.matmul(X_scale, principle), principle\n",
    "\n",
    "def prepare(X, p_num):\n",
    "    if p_num == 'a':\n",
    "        return copy.deepcopy(X)\n",
    "    elif p_num == 'b':\n",
    "        return preprocessing.scale(X, with_mean=True, with_std=True)\n",
    "    elif p_num == 'c':\n",
    "        X_scale = preprocessing.scale(X, with_mean=True, with_std=False)\n",
    "        new_feature, principle = PCA(X_scale)\n",
    "        return new_feature, principle\n",
    "    elif p_num == 'd':\n",
    "        X_scale = preprocessing.scale(X, with_mean=True, with_std=True)\n",
    "        new_feature, principle = PCA(X_scale)\n",
    "        return new_feature, principle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moral-valuable",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### data ######\n",
    "digits = datasets.load_breast_cancer()\n",
    "X = digits.data\n",
    "Y = digits.target\n",
    "kf = KFold(n_splits=10, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assisted-edmonton",
   "metadata": {},
   "outputs": [],
   "source": [
    "### part a ###\n",
    "auc_all = []\n",
    "tprs = []\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = Y[train_index], Y[test_index]\n",
    "    X_train = prepare(X_train, 'a')\n",
    "    mlp = MLPClassifier(hidden_layer_sizes=(16,16), \n",
    "                           max_iter=50, batch_size=32, verbose=False)\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.filterwarnings(\"ignore\", category=ConvergenceWarning, module=\"sklearn\")\n",
    "        mlp.fit(X_train, y_train)\n",
    "    X_test = prepare(X_test, 'a')\n",
    "    y_pred = mlp.predict_proba(X_test)[:, 1]\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred)\n",
    "    auc = metrics.auc(fpr, tpr)\n",
    "    auc_all.append(auc)\n",
    "    interp_tpr = np.interp(mean_fpr, fpr, tpr)\n",
    "    interp_tpr[0] = 0.0\n",
    "    tprs.append(interp_tpr)\n",
    "auc_mean = round(np.mean(auc_all),2)\n",
    "auc_std = round(np.std(auc_all) / math.sqrt(10),3)\n",
    "mean_tpr = np.mean(tprs, axis=0)\n",
    "fig, axs = plt.subplots(1, 1, gridspec_kw={'hspace': 0.1, 'wspace': 0.2, 'bottom': 0.13, \n",
    "                                    'top': 0.9, 'right':0.995, 'left':0.17}, figsize=(5,3))\n",
    "axs.plot(mean_fpr, mean_tpr, label=f'part (a) mean:{auc_mean}\\n confi. interval: {auc_std}', lw=2.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "artificial-welding",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display = metrics.RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=auc,\n",
    "#                                    estimator_name='part (a)')\n",
    "# display.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moving-serve",
   "metadata": {},
   "outputs": [],
   "source": [
    "### part b ###\n",
    "auc_all = []\n",
    "tprs = []\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = Y[train_index], Y[test_index]\n",
    "    X_train = prepare(X_train, 'b')\n",
    "    mlp = MLPClassifier(hidden_layer_sizes=(16,16), \n",
    "                           max_iter=50, batch_size=32, verbose=False)\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.filterwarnings(\"ignore\", category=ConvergenceWarning, module=\"sklearn\")\n",
    "        mlp.fit(X_train, y_train)\n",
    "    X_test = prepare(X_test, 'b')\n",
    "    y_pred = mlp.predict_proba(X_test)[:, 1]\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred)\n",
    "    auc = metrics.auc(fpr, tpr)\n",
    "    auc_all.append(auc)\n",
    "    interp_tpr = np.interp(mean_fpr, fpr, tpr)\n",
    "    interp_tpr[0] = 0.0\n",
    "    tprs.append(interp_tpr)\n",
    "auc_mean = round(np.mean(auc_all),2)\n",
    "auc_std = round(np.std(auc_all) / math.sqrt(10),3)\n",
    "mean_tpr = np.mean(tprs, axis=0)\n",
    "\n",
    "axs.plot(mean_fpr, mean_tpr, label=f'part (b) mean:{auc_mean}\\n confi. interval: {auc_std}', lw=2.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wrapped-passion",
   "metadata": {},
   "outputs": [],
   "source": [
    "### part c ###\n",
    "auc_all = []\n",
    "tprs = []\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = Y[train_index], Y[test_index]\n",
    "    X_train, principle = prepare(X_train, 'c')\n",
    "    mlp = MLPClassifier(hidden_layer_sizes=(16,16), \n",
    "                           max_iter=50, batch_size=32, verbose=False)\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.filterwarnings(\"ignore\", category=ConvergenceWarning, module=\"sklearn\")\n",
    "        mlp.fit(X_train, y_train)\n",
    "    X_test_scale = preprocessing.scale(X_test, with_mean=True, with_std=False)\n",
    "    X_test = np.matmul(X_test_scale, principle)\n",
    "    y_pred = mlp.predict_proba(X_test)[:, 1]\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred)\n",
    "    auc = metrics.auc(fpr, tpr)\n",
    "    auc_all.append(auc)\n",
    "    interp_tpr = np.interp(mean_fpr, fpr, tpr)\n",
    "    interp_tpr[0] = 0.0\n",
    "    tprs.append(interp_tpr)\n",
    "auc_mean = round(np.mean(auc_all),2)\n",
    "auc_std = round(np.std(auc_all) / math.sqrt(10),3)\n",
    "mean_tpr = np.mean(tprs, axis=0)\n",
    "\n",
    "axs.plot(mean_fpr, mean_tpr, label=f'part (c) mean:{auc_mean}\\n confi. interval: {auc_std}', lw=2.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fuzzy-interim",
   "metadata": {},
   "outputs": [],
   "source": [
    "### part d ###\n",
    "auc_all = []\n",
    "tprs = []\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = Y[train_index], Y[test_index]\n",
    "    X_train, principle = prepare(X_train, 'd')\n",
    "    mlp = MLPClassifier(hidden_layer_sizes=(16,16), \n",
    "                           max_iter=50, batch_size=32, verbose=False)\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.filterwarnings(\"ignore\", category=ConvergenceWarning, module=\"sklearn\")\n",
    "        mlp.fit(X_train, y_train)\n",
    "    X_test_scale = preprocessing.scale(X_test, with_mean=True, with_std=True)\n",
    "    X_test = np.matmul(X_test_scale, principle)\n",
    "    y_pred = mlp.predict_proba(X_test)[:, 1]\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred)\n",
    "    auc = metrics.auc(fpr, tpr)\n",
    "    auc_all.append(auc)\n",
    "    interp_tpr = np.interp(mean_fpr, fpr, tpr)\n",
    "    interp_tpr[0] = 0.0\n",
    "    tprs.append(interp_tpr)\n",
    "auc_mean = round(np.mean(auc_all),2)\n",
    "auc_std = round(np.std(auc_all) / math.sqrt(10),3)\n",
    "mean_tpr = np.mean(tprs, axis=0)\n",
    "\n",
    "axs.plot(mean_fpr, mean_tpr, label=f'part (d) mean:{auc_mean}\\n confi. interval: {auc_std}', lw=2.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "soviet-maker",
   "metadata": {},
   "outputs": [],
   "source": [
    "axs.set_title('ROC and AUC mean/std (marked in legend)')\n",
    "axs.grid(which='major', axis='both', ls='dashed', zorder=0)\n",
    "axs.set_xlabel('TPR')\n",
    "axs.legend()\n",
    "# axs[0].set_title('Training Acc.')\n",
    "# axs[1].set_title('Testing Acc.')\n",
    "axs.set_ylabel('FPR')\n",
    "fig.savefig(f'plots/p1.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "secret-abortion",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
